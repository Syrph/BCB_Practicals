{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "ir",
      "display_name": "R",
      "language": "R"
    },
    "language_info": {
      "name": "R",
      "codemirror_mode": "r",
      "pygments_lexer": "r",
      "mimetype": "text/x-r-source",
      "file_extension": ".r",
      "version": "3.6.3"
    },
    "colab": {
      "name": "Practical 3.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUI-qf7916qU"
      },
      "source": [
        "## Phylogenetic models in R\n",
        "\n",
        "### 1. Introduction and resources\n",
        "\n",
        "This practical should be a refresher on linear models in `R`, before introducing you to a phylogentic least squares model, or a PGLS. Because species that are closely related often share similar traits, this means we can't treat them as statistically independent. However, if we look at how the traits are spread throughout the tree, we can 'control' for this non-independance. \n",
        "We'll go into more detail when we run our PGLS. \n",
        "\n",
        "### 2. Linear models\n",
        "\n",
        "For this pratical we'll be working data from the family Anatidae (ducks) to investigate Bergmannâ€™s rule, if there is a relationship between latitude and body mass. \n",
        "First, we'll load in the data and inspect it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THjMv4JD2N41"
      },
      "source": [
        "dir.create(\"My Git Repo\")\n",
        "git2r::clone(\"https://github.com/Syrph/BCB_Practicals\", \"My Git Repo\")\n",
        "setwd(\"My Git Repo\")\n",
        "system(\"sudo apt-get install libgdal-dev libproj-dev libgeos-dev libudunits2-dev libv8-dev libprotobuf-dev libjq-dev\")\n",
        "source(\"install.R\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "n_xtOBXU16qW"
      },
      "source": [
        "# Load the duck latitudinal and bodymass data\n",
        "duck_data <- read.csv(\"duck_data.csv\",h=T) \n",
        "\n",
        "# Check it's been imported\n",
        "str(duck_data)\n",
        "head(duck_data)\n",
        "\n",
        "# Remove any NAs in the data (make sure to check you're not loosing too much data!)\n",
        "duck_data <- na.omit(duck_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bc1mHMHu16qh"
      },
      "source": [
        "The midpoint latitude is the center of the distribution of each species. Because we're interested in the distance from equator, we'll use the `abs()` function to convert our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "HIsuYrg316qi"
      },
      "source": [
        "duck_data$abs_latitude <- abs(duck_data$Latitude)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGbxuwM516qn"
      },
      "source": [
        "We'll start by looking at the relationship between body mass and latitude using a scatterplot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "yC_uecB016qn"
      },
      "source": [
        "plot(Body_Mass ~ abs_latitude, data = duck_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YKXEd-W16qr"
      },
      "source": [
        "Now there doesn't seem to be much of a relationship at all from our plot. However, to double check we should look at the spread of data for both variables. In particular, body mass is often scaled logarithmically, with lots of small species and fewer large ones. Therefore we might not be seeing the true relationship! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "LM1rwtj816qw"
      },
      "source": [
        "# We'll use a histogram to look at the spread.\n",
        "hist(duck_data$Body_Mass)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9ICatU916q0"
      },
      "source": [
        "As we suspected! The histogram suggests a log-normal distribution. If we take logs we might see a more normal distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "IF0dsj-316q0"
      },
      "source": [
        "duck_data$log_BM <- log(duck_data$Body_Mass)\n",
        "hist(duck_data$log_BM)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZflbxiu16q3"
      },
      "source": [
        "Now we've got some data that resembles a more normal distribution! We'll now look at the spread of latitude."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "yG2rLRrH16q3"
      },
      "source": [
        "hist(duck_data$abs_latitude)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEDZGIgi16q6"
      },
      "source": [
        "Not great, but no obvious signs of left or right skews in the data, so we can work with it. We'll leave it as it is.\n",
        "Let's look at the new relationship between the two variables:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "cH5jnj3116q6"
      },
      "source": [
        "plot(log_BM ~ abs_latitude, data = duck_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHyA96Ns16q9"
      },
      "source": [
        "Now we're starting to see some kind of relationship! There's a lot of spread to the points, but we can see the smallest species at the lowest latitudes, and the largest at the highest. To really find out if there's a relationship we can test our hypothesis with a linear model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "bZa-8c9s16q9"
      },
      "source": [
        "# Run a basic linear model. We separate our dependant variables from predictors using a tilda ~\n",
        "duck_model <- lm(log_BM ~ abs_latitude, data = duck_data)\n",
        "\n",
        "# Inspect our linear model\n",
        "summary(duck_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkUjWHSn16q_"
      },
      "source": [
        "Now we can investigate if there is a relationship. There's quite a lot going on with our output, but for this practical we'll focus on just a few main things:\n",
        "\n",
        "`Coefficients`: This tells us about our predictors in the model. In this one there's 2, the intercept, and latitude.  We'll break each section down further.\n",
        "\n",
        "`Estimate`: The estimate of our coefficients tells us what value it should have. For the intercept this will be the point that that crosses across the y axis. For latitude, this will be the gradient of the relationship between latitude and body mass. \n",
        "\n",
        "`Std. Error`: This shows how much faith we have in our estimates. We're fairly certain that our estimates will fall within the range: Estimate +- Standard Error. \n",
        "\n",
        "`t value`: This is our test statistic. In a linear model we're testing if each of our estimate values are significantly different from zero. If our estimate and standard error don't overlap zero, it normally means they are significant. \n",
        "\n",
        "`Pr(>|t|)`: This is our p values for each predictor. This is calculated by weighing up the degrees of freedom against our test statistic, and tells us what the chance is that we observed the same pattern in our data given that there was no relationship, i.e. the null hypothesis is true. \n",
        "\n",
        "`Multiple R-squared`: This tells us how much of the variation in our response variable is explained by our model. Large values are better, but often in macro-evolution we see smaller values. Because traits at a macro scale are often driven by multiple selection pressures, which may sometimes be species-specific, we typically explain less variation than smaller more targeted studies. \n",
        "\n",
        "`Adjusted R squared`: This also explains the varition in response, but penalises us for including more predictors. This reduces the chances of over-fitting models with lots of predictors that don't contribute much. This is the R-squared that tends to be reported in publications. \n",
        "\n",
        "`F Statistc` & `DF` & `p-value`: The last line reports the overall results of our model. When reporting the statistic tests in the results section, we tend to quote these values for the model. This test is comparing our model line against a flat horizontal line at the mean body mass. Simply put, does our latitude model explain more of the variance in body mass than the mean. This is easiest to explain with a quick example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "jIjzQ-Wc16rA"
      },
      "source": [
        "# Create some data\n",
        "x <- c(12,18,21, 36, 44, 54, 59)\n",
        "y <- c(2, 4, 7, 11, 12, 14, 15)\n",
        "\n",
        "# Create a linear model based only on the mean of body mass\n",
        "mean <- lm(y ~ 1)\n",
        "\n",
        "# Create a linear model where x predicts y\n",
        "linear <- lm(y ~ x)\n",
        "\n",
        "# Create a plot window with one row and two columns\n",
        "par(mfrow =c (1,2))\n",
        "\n",
        "# Plot our data for the mean\n",
        "plot(x,y, xlim = c(0,60), ylim =c(0,15), main = \"Mean\") \n",
        "\n",
        "# Add the line of the linear model based on the mean\n",
        "abline(mean, col=\"red\")\n",
        "\n",
        "# Add in lines to show the distance from each point to mean line (the residuals)\n",
        "segments(x, y, x, predict(mean))\n",
        "\n",
        "# Do the same to plot our data with the linear model based on x\n",
        "plot(x,y, xlim = c(0,60), ylim =c(0,15), main = \"Linear\")  \n",
        "abline(linear, col=\"blue\")\n",
        "segments(x, y, x, predict(linear))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ffa9tUA16rD"
      },
      "source": [
        "From the plots we can see that the blue linear model line passes closer to all of our data points than simply using the mean line. The black lines from our data points to the linear model are the residual variation left over once we've accounted for x. This is often referred to as the residuals.\n",
        "\n",
        "The F statistic in our summary output is testing if there is a siginificant difference between the residuals from using our mean line against using our linear model instead. This is weighed up against the number of degrees of freedom to calculate our p-value. \n",
        "\n",
        "Degrees of freedom are often poorly known but are actually quite simple to understand. They are calculated from the number of independent data points in your model, minus the number of predictors. This is to prevent models that over-fit the data. So models with lots of data points have high degrees of freedom which means we need lower F statistic values to be certain of our model. For models with few data points it depends on the number of predictors. If there's few predictors, like in our model, that means that we can accept lower F statistics. We can be more confident in our relationship if we used fewer predictors to describe it. If we use lots of predictors, we can be less certain in our model, because each predictor may explain some of the variation just by chance. Therefore we need a higher F statistic. When you report your models, report both the degrees of freedom and the F statistic alongside your p-value for the whole model. \n",
        "\n",
        "Now that we understand a bit more about our summary report, lets look at it again to investigate the relationship between body mass and latitude. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "rXhTY-Nm16rD"
      },
      "source": [
        "summary(duck_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "trusted": false,
        "id": "aj44SKWL16rG"
      },
      "source": [
        "We can see from our model that both the intercept and latitude are significant predictors. That the intercept is significant isn't very interesting. It means at 0 latitude (the equator), body mass is significantly different from zero. Seeing as it's impossible to have a species with zero body mass, this isn't suprising! What's more interesting is latitude. We can see a significant p-value, so there is a relationship between latitude and body mass. As the estimate is postive, we can see that as latitude increases, so does body mass. For every 1 degree of latitude, log(body mass) increases by 0.012. We can simply convert our body mass back into normal units for a more intuitive value: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "WS-Onccs16rH"
      },
      "source": [
        "# Get the exponential of our estimate\n",
        "exp(0.011639)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtc0YdU316rJ"
      },
      "source": [
        "So for every one degree latitude increase, our model predicts a 1g increase in body weight, supporting Bergmannâ€™s rule. We can see that by plotting our model line with our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "CnzIk9FF16rK"
      },
      "source": [
        "plot(log_BM ~ abs_latitude, data = duck_data)\n",
        "abline(duck_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8iEvP_616rM"
      },
      "source": [
        "Of course, we can see that the spread of data that many points don't fit this line. If we look at the adjusted R-squared, we can see that our model explains roughly 9% of the variation in body size. Most macroevolutionary studies have low R-squared values, so this is quite high! We could potentially increase this more by including other predictors which influence body size. Have a think about what these predictors could be. \n",
        "\n",
        "We can also see from the bottom line of output that our overall model is significant. Because there is only one predictor (except the intercept), this value will be the same as our p-value for body mass.\n",
        "\n",
        "As we've ran a standard linear model, we should also check our residuals to see if they are normally distributed. This is one of the assumptions of parametric tests, and if not we might consider using a generalised linear model instead. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "w2F_ZbXC16rM"
      },
      "source": [
        "# Plot a density curve of the residuals\n",
        "plot(density(duck_model$residuals))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBwSSe8116rO"
      },
      "source": [
        "Our residuals look pretty normally distributed. It's normally good enough just to inspect these plots by eye, to check there's no extreme left or right skew to the distribution. \n",
        "\n",
        "### 3. Phylogenetic Generalised Least Squares Models\n",
        "\n",
        "Up until now we have been treating all our species as independant data points. However, technically this isn't true. Each species is related to each other, and some are more closely related than others. We might expect that closely related species in the same genus are more likely to have a similar body mass than species from different genera. We then come to the conclusion that there are more large species at higher latitudes because they all shared one common ancestor, who happened to be a large species. This would suggest that the evolutionary history of ducks is responsible for the patterns of body mass, rather than a true relationship between latitude and body mass. Fortunately, we can test this using phylogenetically-controlled linear models. One of the easiest to use a PGLS. \n",
        "\n",
        "First let's load up the packages we need and the phylogenetic tree of ducks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "cIIBMkxR16rO"
      },
      "source": [
        "library(ape)\n",
        "library(caper)\n",
        "\n",
        "# Read in the tree\n",
        "duck_tree <- read.tree(\"duck_tree.tre\")\n",
        "plot(duck_tree)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "trusted": false,
        "id": "IAI-oUyt16rQ"
      },
      "source": [
        "We now need to attach our body mass data and tree together, and we can do this by creating a comparative data object from the caper package."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-db8vPXX16rQ"
      },
      "source": [
        "# We need to change the Jetz names so that they match the tip labels. gsub is another function to swap patterns in strings.\n",
        "duck_data$Jetz_Name <- gsub(\" \", \"_\", duck_data$Jetz_Name)\n",
        "\n",
        "# We specify the phylogeny we need, the data, and which column has the tip label names in\n",
        "duck_comp <- comparative.data(phy = duck_tree, data = duck_data, names.col = \"Jetz_Name\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "trusted": false,
        "id": "JYbS-Z0w16rT"
      },
      "source": [
        "We can inspect our comparative data object to check that it's worked. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Qu9Qt4RD16rU"
      },
      "source": [
        "# Return the data \n",
        "duck_comp$data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "TjpGUclr16rW"
      },
      "source": [
        "# Plot the phylogeny\n",
        "plot(duck_comp$phy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "trusted": false,
        "id": "m-YgWSXv16rY"
      },
      "source": [
        "So we can see that our comparative object has worked as it should. Now we can run a pgls to see if information on the phylogeny makes any difference."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "rWQQcJWn16rY"
      },
      "source": [
        "duck_pgls <- pgls(log_BM ~ abs_latitude, data = duck_comp, lambda = \"ML\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "trusted": false,
        "id": "eBPxCAkJ16ra"
      },
      "source": [
        "The code for a pgls looks largely the same. The only difference is that we have a third arguement, which is the lambda value. The lambda value tells us how randomly body mass and latitude are spread throughout the tree. By saying `\"ML\"` we've asked the function to calculate lambda using maximum likelihood methods, rather than give it an exact value. \n",
        "\n",
        "Let's take a look at the results of the pgls."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "R7f1B-uQ16ra"
      },
      "source": [
        "summary(duck_pgls)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "trusted": false,
        "id": "GvaDZ4Hp16rc"
      },
      "source": [
        "The output of the summary look largely the same as our linear model. The key difference is we now have information on the branch length transformations, which shows how our trait is influenced by phylogeny. We can also see that our p-value for latitude is now much higher, and above the 0.05 threshold. When we look at our estimate, we can see that it's a postive value, so the same relationship is there, but we can no longer be confident enough to reject our null hypothesis. This is why for macro-evolutionary studies, we always have to include information on the phylogeny! \n",
        "\n",
        "We should take a second to look at the lambda value. We can plot the profile of our lambda model and see how we came to this number."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "xCWXPUAq16rd"
      },
      "source": [
        "# Get the potential values of lambda\n",
        "lambda_likelihood <- pgls.profile(duck_pgls, which = \"lambda\")\n",
        "\n",
        "# Plot them\n",
        "plot(lambda_likelihood)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "trusted": false,
        "id": "r-AaWvBH16rf"
      },
      "source": [
        "On the horizontal axis we can see potential lambda values, and on the vertical is how likely they are. Red lines show the 95% confidence intervals. This shows that we are fairly confident in our lambda value. It's always worth plotting the our lambda profile, as a flatter line would mean we're less confident in our lambda, and might not have controlled for our phylogeny properly. But what does the lambda value actually do? \n",
        "\n",
        "Lambda is scaled between 0 and 1, and it's easiest to think of it as how much our trait is bunched up in the tree. Values closer to zero suggest that body mass would be spread randomly among the tree, and the phylogeny does not matter. Values closer to one suggest that body mass is organised strongly throughout the tree, with closer species having more similar sizes. \n",
        "\n",
        "For an excellent explanation of lambda values, check out this paper by Natalie Cooper at the Natural History Museum, who helped write the second practical on this course. \n",
        "\n",
        "https://royalsocietypublishing.org/doi/full/10.1098/rstb.2012.0341 \n",
        "\n",
        "What the lambda value actually does is change the length of the branches on the tree, to reflect how body mass is related between species. We can visualise this by plotting trees with different lambda values. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_fbAd06f16rf"
      },
      "source": [
        "# Load the package geiger that has the rescale function. You'll have to install it if you're in Rstudio on your own laptops.\n",
        "library(geiger)\n",
        "\n",
        "# We'll create six trees with different lambda values \n",
        "lambda_1_tree <- rescale(duck_tree, \"lambda\", 1)\n",
        "lambda_0.8_tree <- rescale(duck_tree, \"lambda\", 0.8)\n",
        "lambda_0.6_tree <- rescale(duck_tree, \"lambda\", 0.6)\n",
        "lambda_0.4_tree <- rescale(duck_tree, \"lambda\", 0.4)\n",
        "lambda_0.2_tree <- rescale(duck_tree, \"lambda\", 0.2)\n",
        "lambda_0_tree <- rescale(duck_tree, \"lambda\", 0)\n",
        "\n",
        "# Now we'll plot them alongside each other to see the difference\n",
        "\n",
        "# Change the number of plots and resize the window\n",
        "par(mfrow = c(2,3))\n",
        "options(repr.plot.width=15, repr.plot.height=15)\n",
        "\n",
        "plot(lambda_1_tree, show.tip.label = FALSE, direction = \"downwards\", main = \"1.0\")\n",
        "plot(lambda_0.8_tree, show.tip.label = FALSE, direction = \"downwards\", main = \"0.8\")\n",
        "plot(lambda_0.6_tree, show.tip.label = FALSE, direction = \"downwards\", main = \"0.6\")\n",
        "plot(lambda_0.4_tree, show.tip.label = FALSE, direction = \"downwards\", main = \"0.4\")\n",
        "plot(lambda_0.2_tree, show.tip.label = FALSE, direction = \"downwards\", main = \"0.2\")\n",
        "plot(lambda_0_tree, show.tip.label = FALSE, direction = \"downwards\", main = \"0.0\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "trusted": false,
        "id": "GBuahsE_16rh"
      },
      "source": [
        "What's actually happening is the lambda value shortens all the interal branches (everything except the tips). This reduces the difference between species. In the last plot we can see a lambda value of zero, and all the branches are equally close to the root, and therefore each other. This means that all our species are now independent points, and if we ran a pgls we would get similar results to a linear model. Try it out running a pgls with different lambda values and see what what happens!\n",
        "\n",
        "Don't worry if you struggled to understand any of this! Lambda values can be tricky to get your head around. At this stage, it's only important to be aware that a pgls uses a lambda value to decide how much to weight up the importance of the phylogeny. "
      ]
    }
  ]
}