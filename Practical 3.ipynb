{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "ir",
      "display_name": "R",
      "language": "R"
    },
    "language_info": {
      "name": "R",
      "codemirror_mode": "r",
      "pygments_lexer": "r",
      "mimetype": "text/x-r-source",
      "file_extension": ".r",
      "version": "3.6.3"
    },
    "colab": {
      "name": "Practical_3.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIrf0391I5w6"
      },
      "source": [
        "## Phylogenetic models in R"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THjMv4JD2N41",
        "cellView": "form"
      },
      "source": [
        "#@title ### Run to set up notebook (Takes ~ 15 minutes).\n",
        "# Clone github repository, install spatial dependencies for linux, install R packages\n",
        "dir.create(\"My Git Repo\")\n",
        "git2r::clone(\"https://github.com/Syrph/BCB_Practicals\", \"My Git Repo\")\n",
        "setwd(\"My Git Repo\")\n",
        "system(\"sudo apt-get update\")\n",
        "system(\"sudo apt-get install libgdal-dev libproj-dev libgeos-dev libudunits2-dev libv8-dev libprotobuf-dev libjq-dev\")\n",
        "source(\"install.R\")\n",
        "\n",
        "# Load in all the accip maps and combine them into one big sp datafame\n",
        "library(rgdal)\n",
        "library(raster)\n",
        "library(dplyr)\n",
        "\n",
        "# Get the file names that are Rdata objects\n",
        "file_names <- list.files()\n",
        "indices <- grep(\"*Rdata\", file_names)\n",
        "file_names <- file_names[indices]\n",
        "\n",
        "# load in the first map and create a vector ready\n",
        "load(\"Accipiter_albogularis_maps.Rdata\")\n",
        "assign(\"Accipiter_albogularis_maps\", species_map)\n",
        "Accip_maps <- Accipiter_albogularis_maps\n",
        "\n",
        "# Load in the rest of the maps and combine them\n",
        "for (file in file_names[2:248]){\n",
        "  name <- gsub(\".Rdata\", \"\", file)\n",
        "  load(file)\n",
        "  assign(name, species_map)\n",
        "  Accip_maps <- rbind(Accip_maps, get(name))\n",
        "}\n",
        "\n",
        "# Save it back as an R.data object\n",
        "save(Accip_maps, file = \"Accipitridae_maps.Rdata\")\n",
        "rm(list=ls())\n",
        "\n",
        "# Remove the packages for students to load back in later\n",
        "detach(\"package:raster\", unload = TRUE)\n",
        "detach(\"package:rgdal\", unload = TRUE)\n",
        "detach(\"package:dplyr\", unload= TRUE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkOpJzHGI9U6"
      },
      "source": [
        "### 1. Introduction and resources\n",
        "\n",
        "This practical should be a refresher on linear models in `R`, before introducing you to a phylogentic least squares model, or a PGLS. Because species that are closely related often share similar traits, this means we can't treat them as statistically independent. However, if we look at how the traits are spread throughout the tree, we can 'control' for this non-independance. We'll go into more detail when we run our PGLS. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUI-qf7916qU"
      },
      "source": [
        "### 2. Linear models\n",
        "\n",
        "For this pratical we'll be working data from the family Anatidae (ducks) to investigate Bergmannâ€™s rule, if there is a relationship between latitude and body mass. \n",
        "First, we'll load in the data and inspect it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "n_xtOBXU16qW"
      },
      "source": [
        "# Load the duck latitudinal and bodymass data\n",
        "duck_data <- read.csv(\"duck_data.csv\",h=T) \n",
        "\n",
        "# Check it's been imported\n",
        "str(duck_data)\n",
        "head(duck_data)\n",
        "\n",
        "# Remove any NAs in the data (make sure to check you're not loosing too much data!)\n",
        "duck_data <- na.omit(duck_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bc1mHMHu16qh"
      },
      "source": [
        "The midpoint latitude is the center of the distribution of each species. Because we're interested in the distance from equator, we'll use the `abs()` function to convert our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "HIsuYrg316qi"
      },
      "source": [
        "duck_data$abs_latitude <- abs(duck_data$Latitude)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGbxuwM516qn"
      },
      "source": [
        "We'll start by looking at the relationship between body mass and latitude using a scatterplot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "yC_uecB016qn"
      },
      "source": [
        "plot(Body_Mass ~ abs_latitude, data = duck_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YKXEd-W16qr"
      },
      "source": [
        "Now there doesn't seem to be much of a relationship at all from our plot. However, to double check we should look at the spread of data for both variables. In particular, body mass is often scaled logarithmically, with lots of small species and fewer large ones. Therefore we might not be seeing the true relationship! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "LM1rwtj816qw"
      },
      "source": [
        "# We'll use a histogram to look at the spread.\n",
        "hist(duck_data$Body_Mass)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9ICatU916q0"
      },
      "source": [
        "As we suspected! The histogram suggests a log-normal distribution. If we take logs we might see a more normal distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "IF0dsj-316q0"
      },
      "source": [
        "duck_data$log_BM <- log(duck_data$Body_Mass)\n",
        "hist(duck_data$log_BM)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZflbxiu16q3"
      },
      "source": [
        "Now we've got some data that resembles a more normal distribution! We'll now look at the spread of latitude."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "yG2rLRrH16q3"
      },
      "source": [
        "hist(duck_data$abs_latitude)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEDZGIgi16q6"
      },
      "source": [
        "Not great, but no obvious signs of left or right skews in the data, so we can work with it. We'll leave it as it is.\n",
        "Let's look at the new relationship between the two variables:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "cH5jnj3116q6"
      },
      "source": [
        "plot(log_BM ~ abs_latitude, data = duck_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHyA96Ns16q9"
      },
      "source": [
        "Now we're starting to see some kind of relationship! There's a lot of spread to the points, but we can see the smallest species at the lowest latitudes, and the largest at the highest. To really find out if there's a relationship we can test our hypothesis with a linear model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "bZa-8c9s16q9"
      },
      "source": [
        "# Run a basic linear model. We separate our dependant variables from predictors using a tilda ~\n",
        "duck_model <- lm(log_BM ~ abs_latitude, data = duck_data)\n",
        "\n",
        "# Inspect our linear model\n",
        "summary(duck_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkUjWHSn16q_"
      },
      "source": [
        "Now we can investigate if there is a relationship. There's quite a lot going on with our output, but for this practical we'll focus on just a few main things:\n",
        "\n",
        "`Coefficients`: This tells us about our predictors in the model. In this one there's 2, the intercept, and latitude.  We'll break each section down further.\n",
        "\n",
        "`Estimate`: The estimate of our coefficients tells us what value it should have. For the intercept this will be the point that that crosses across the y axis. For latitude, this will be the gradient of the relationship between latitude and body mass. \n",
        "\n",
        "`Std. Error`: This shows how much faith we have in our estimates. We're fairly certain that our estimates will fall within the range: Estimate +- Standard Error. \n",
        "\n",
        "`t value`: This is our test statistic. In a linear model we're testing if each of our estimate values are significantly different from zero. If our estimate and standard error don't overlap zero, it normally means they are significant. \n",
        "\n",
        "`Pr(>|t|)`: This is our p values for each predictor. This is calculated by weighing up the degrees of freedom against our test statistic, and tells us what the chance is that we observed the same pattern in our data given that there was no relationship, i.e. the null hypothesis is true. \n",
        "\n",
        "`Multiple R-squared`: This tells us how much of the variation in our response variable is explained by our model. Large values are better, but often in macro-evolution we see smaller values. Because traits at a macro scale are often driven by multiple selection pressures, which may sometimes be species-specific, we typically explain less variation than smaller more targeted studies. \n",
        "\n",
        "`Adjusted R squared`: This also explains the varition in response, but penalises us for including more predictors. This reduces the chances of over-fitting models with lots of predictors that don't contribute much. This is the R-squared that tends to be reported in publications. \n",
        "\n",
        "`F Statistc` & `DF` & `p-value`: The last line reports the overall results of our model. When reporting the statistic tests in the results section, we tend to quote these values for the model. This test is comparing our model line against a flat horizontal line at the mean body mass. Simply put, does our latitude model explain more of the variance in body mass than the mean. This is easiest to explain with a quick example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "jIjzQ-Wc16rA"
      },
      "source": [
        "# Create some data\n",
        "x <- c(12,18,21, 36, 44, 54, 59)\n",
        "y <- c(2, 4, 7, 11, 12, 14, 15)\n",
        "\n",
        "# Create a linear model based only on the mean of body mass\n",
        "mean <- lm(y ~ 1)\n",
        "\n",
        "# Create a linear model where x predicts y\n",
        "linear <- lm(y ~ x)\n",
        "\n",
        "# Create a plot window with one row and two columns\n",
        "par(mfrow =c (1,2))\n",
        "\n",
        "# Plot our data for the mean\n",
        "plot(x,y, xlim = c(0,60), ylim =c(0,15), main = \"Mean\") \n",
        "\n",
        "# Add the line of the linear model based on the mean\n",
        "abline(mean, col=\"red\")\n",
        "\n",
        "# Add in lines to show the distance from each point to mean line (the residuals)\n",
        "segments(x, y, x, predict(mean))\n",
        "\n",
        "# Do the same to plot our data with the linear model based on x\n",
        "plot(x,y, xlim = c(0,60), ylim =c(0,15), main = \"Linear\")  \n",
        "abline(linear, col=\"blue\")\n",
        "segments(x, y, x, predict(linear))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ffa9tUA16rD"
      },
      "source": [
        "From the plots we can see that the blue linear model line passes closer to all of our data points than simply using the mean line. The black lines from our data points to the linear model are the residual variation left over once we've accounted for x. This is often referred to as the residuals.\n",
        "\n",
        "The F statistic in our summary output is testing if there is a siginificant difference between the residuals from using our mean line against using our linear model instead. This is weighed up against the number of degrees of freedom to calculate our p-value. \n",
        "\n",
        "Degrees of freedom are often poorly known but are actually quite simple to understand. They are calculated from the number of independent data points in your model, minus the number of predictors. This is to prevent models that over-fit the data. So models with lots of data points have high degrees of freedom which means we need lower F statistic values to be certain of our model. For models with few data points it depends on the number of predictors. If there's few predictors, like in our model, that means that we can accept lower F statistics. We can be more confident in our relationship if we used fewer predictors to describe it. If we use lots of predictors, we can be less certain in our model, because each predictor may explain some of the variation just by chance. Therefore we need a higher F statistic. When you report your models, report both the degrees of freedom and the F statistic alongside your p-value for the whole model. \n",
        "\n",
        "Now that we understand a bit more about our summary report, lets look at it again to investigate the relationship between body mass and latitude. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "rXhTY-Nm16rD"
      },
      "source": [
        "summary(duck_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "trusted": false,
        "id": "aj44SKWL16rG"
      },
      "source": [
        "We can see from our model that both the intercept and latitude are significant predictors. That the intercept is significant isn't very interesting. It means at 0 latitude (the equator), body mass is significantly different from zero. Seeing as it's impossible to have a species with zero body mass, this isn't suprising! What's more interesting is latitude. We can see a significant p-value, so there is a relationship between latitude and body mass. As the estimate is postive, we can see that as latitude increases, so does body mass. For every 1 degree of latitude, log(body mass) increases by 0.012. We can simply convert our body mass back into normal units for a more intuitive value: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "WS-Onccs16rH"
      },
      "source": [
        "# Get the exponential of our estimate\n",
        "exp(0.011639)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtc0YdU316rJ"
      },
      "source": [
        "So for every one degree latitude increase, our model predicts a 1g increase in body weight, supporting Bergmannâ€™s rule. We can see that by plotting our model line with our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "CnzIk9FF16rK"
      },
      "source": [
        "plot(log_BM ~ abs_latitude, data = duck_data)\n",
        "abline(duck_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8iEvP_616rM"
      },
      "source": [
        "Of course, we can see that the spread of data that many points don't fit this line. If we look at the adjusted R-squared, we can see that our model explains roughly 9% of the variation in body size. Most macroevolutionary studies have low R-squared values, so this is quite high! We could potentially increase this more by including other predictors which influence body size. Have a think about what these predictors could be. \n",
        "\n",
        "We can also see from the bottom line of output that our overall model is significant. Because there is only one predictor (except the intercept), this value will be the same as our p-value for body mass.\n",
        "\n",
        "As we've ran a standard linear model, we should also check our residuals to see if they are normally distributed. This is one of the assumptions of parametric tests, and if not we might consider using a generalised linear model instead. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "w2F_ZbXC16rM"
      },
      "source": [
        "# Plot a density curve of the residuals\n",
        "plot(density(duck_model$residuals))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBwSSe8116rO"
      },
      "source": [
        "Our residuals look pretty normally distributed. It's normally good enough just to inspect these plots by eye, to check there's no extreme left or right skew to the distribution. \n",
        "\n",
        "### 3. Phylogenetic Generalised Least Squares Models\n",
        "\n",
        "Up until now we have been treating all our species as independant data points. However, technically this isn't true. Each species is related to each other, and some are more closely related than others. We might expect that closely related species in the same genus are more likely to have a similar body mass than species from different genera. We then come to the conclusion that there are more large species at higher latitudes because they all shared one common ancestor, who happened to be a large species. This would suggest that the evolutionary history of ducks is responsible for the patterns of body mass, rather than a true relationship between latitude and body mass. Fortunately, we can test this using phylogenetically-controlled linear models. One of the easiest to use a PGLS. \n",
        "\n",
        "First let's load up the packages we need and the phylogenetic tree of ducks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "cIIBMkxR16rO"
      },
      "source": [
        "library(ape)\n",
        "library(caper)\n",
        "\n",
        "# Read in the tree\n",
        "duck_tree <- read.tree(\"duck_tree.tre\")\n",
        "plot(duck_tree)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "trusted": false,
        "id": "IAI-oUyt16rQ"
      },
      "source": [
        "We now need to attach our body mass data and tree together, and we can do this by creating a comparative data object from the caper package."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-db8vPXX16rQ"
      },
      "source": [
        "# We need to change the Jetz names so that they match the tip labels. gsub is another function to swap patterns in strings.\n",
        "duck_data$Jetz_Name <- gsub(\" \", \"_\", duck_data$Jetz_Name)\n",
        "\n",
        "# We specify the phylogeny we need, the data, and which column has the tip label names in\n",
        "duck_comp <- comparative.data(phy = duck_tree, data = duck_data, names.col = \"Jetz_Name\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "trusted": false,
        "id": "JYbS-Z0w16rT"
      },
      "source": [
        "We can inspect our comparative data object to check that it's worked. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Qu9Qt4RD16rU"
      },
      "source": [
        "# Return the data \n",
        "duck_comp$data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "TjpGUclr16rW"
      },
      "source": [
        "# Plot the phylogeny\n",
        "plot(duck_comp$phy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "trusted": false,
        "id": "m-YgWSXv16rY"
      },
      "source": [
        "So we can see that our comparative object has worked as it should. Now we can run a pgls to see if information on the phylogeny makes any difference."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "rWQQcJWn16rY"
      },
      "source": [
        "duck_pgls <- pgls(log_BM ~ abs_latitude, data = duck_comp, lambda = \"ML\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "trusted": false,
        "id": "eBPxCAkJ16ra"
      },
      "source": [
        "The code for a pgls looks largely the same. The only difference is that we have a third arguement, which is the lambda value. The lambda value tells us how randomly body mass and latitude are spread throughout the tree. By saying `\"ML\"` we've asked the function to calculate lambda using maximum likelihood methods, rather than give it an exact value. \n",
        "\n",
        "Let's take a look at the results of the pgls."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "R7f1B-uQ16ra"
      },
      "source": [
        "summary(duck_pgls)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "trusted": false,
        "id": "GvaDZ4Hp16rc"
      },
      "source": [
        "The output of the summary look largely the same as our linear model. The key difference is we now have information on the branch length transformations, which shows how our trait is influenced by phylogeny. We can also see that our p-value for latitude is now much higher, and above the 0.05 threshold. When we look at our estimate, we can see that it's a postive value, so the same relationship is there, but we can no longer be confident enough to reject our null hypothesis. This is why for macro-evolutionary studies, we always have to include information on the phylogeny!\n",
        "\n",
        "We should take a second to look at the lambda value. Ours is 0.98 according to the pgls summary. But what does it mean?\n",
        "\n",
        "Lambda is scaled between 0 and 1, and it's easiest to think of it as how much our trait is bunched up in the tree. Values closer to zero suggest that body mass would be spread randomly among the tree, and the phylogeny does not matter. Values closer to one suggest that body mass is organised strongly throughout the tree, with closer species having more similar sizes.\n",
        "\n",
        "For an excellent explanation of lambda values, check out this paper by Natalie Cooper at the Natural History Museum, who helped write the second practical on this course.\n",
        "\n",
        "https://royalsocietypublishing.org/doi/full/10.1098/rstb.2012.0341\n",
        "\n",
        "What the lambda value actually does is change the length of the branches on the tree, to reflect how body mass is related between species. We can visualise this by plotting trees with different lambda values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_fbAd06f16rf"
      },
      "source": [
        "# Load the package geiger that has the rescale function. You'll have to install it if you're in Rstudio on your own laptops.\n",
        "library(geiger)\n",
        "\n",
        "# We'll create six trees with different lambda values \n",
        "lambda_1_tree <- rescale(duck_tree, \"lambda\", 1)\n",
        "lambda_0.8_tree <- rescale(duck_tree, \"lambda\", 0.8)\n",
        "lambda_0.6_tree <- rescale(duck_tree, \"lambda\", 0.6)\n",
        "lambda_0.4_tree <- rescale(duck_tree, \"lambda\", 0.4)\n",
        "lambda_0.2_tree <- rescale(duck_tree, \"lambda\", 0.2)\n",
        "lambda_0_tree <- rescale(duck_tree, \"lambda\", 0)\n",
        "\n",
        "# Now we'll plot them alongside each other to see the difference\n",
        "\n",
        "# Change the number of plots and resize the window\n",
        "par(mfrow = c(2,3))\n",
        "options(repr.plot.width=15, repr.plot.height=15)\n",
        "\n",
        "plot(lambda_1_tree, show.tip.label = FALSE, direction = \"downwards\", main = \"1.0\")\n",
        "plot(lambda_0.8_tree, show.tip.label = FALSE, direction = \"downwards\", main = \"0.8\")\n",
        "plot(lambda_0.6_tree, show.tip.label = FALSE, direction = \"downwards\", main = \"0.6\")\n",
        "plot(lambda_0.4_tree, show.tip.label = FALSE, direction = \"downwards\", main = \"0.4\")\n",
        "plot(lambda_0.2_tree, show.tip.label = FALSE, direction = \"downwards\", main = \"0.2\")\n",
        "plot(lambda_0_tree, show.tip.label = FALSE, direction = \"downwards\", main = \"0.0\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "trusted": false,
        "id": "TCWJMELfk1RT"
      },
      "source": [
        "What's actually happening is the lambda value shortens all the interal branches (everything except the tips). This reduces the difference between species. In the last plot we can see a lambda value of zero, and all the branches are equally close to the root, and therefore each other. This means that all our species are now independent points, and if we ran a pgls we would get similar results to a linear model. Try it out running a pgls with different lambda values and see what what happens!\n",
        "\n",
        "We can plot the profile of the lambda value from our pgls and see how we came to this number.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "xCWXPUAq16rd"
      },
      "source": [
        "# Get the potential values of lambda\n",
        "lambda_likelihood <- pgls.profile(duck_pgls, which = \"lambda\")\n",
        "\n",
        "# Plot them\n",
        "plot(lambda_likelihood)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "trusted": false,
        "id": "GBuahsE_16rh"
      },
      "source": [
        "On the horizontal axis we can see potential lambda values, and on the vertical is how likely they are. Red lines show the 95% confidence intervals. This shows that we are fairly confident in our lambda value. It's always worth plotting the our lambda profile, as a flatter line would mean we're less confident in our lambda, and might not have controlled for our phylogeny properly. Also be wary of smaller phylogenies, as the lambda value is harder to estimate. Try and pick a group with more than 100 species for your coursework just to be safe. \n",
        "\n",
        "Don't worry if you struggled to understand any of this! Lambda values can be tricky to get your head around. At this stage, it's only important to be aware that a pgls uses a lambda value to decide how much to weight up the importance of the phylogeny. \n",
        "\n",
        "For more information on using a pgls check out this very useful papers that are aimed at beginners. In particular chapeter 6 which you find on researchgate: \n",
        "\n",
        "http://www.mpcm-evolution.com/book-sections/part-introduction/5-primer-phylogenetic-generalised-least-squares \n",
        "\n",
        "http://www.mpcm-evolution.com/book-sections/part-introduction/6-statistical-issues-assumptions-phylogenetic-generalised-least-squares\n",
        "\n",
        "https://onlinelibrary.wiley.com/doi/full/10.1111/j.1420-9101.2009.01757.x\n",
        "\n",
        "### 4. Rapport's Rule\n",
        "\n",
        "For your coursework you might choose to investigate Rapport's rule, does range size increase with latitude. To do this we're going to use some of the mapping skills that we learnt from Practical 1 to extract range size and latitude. For this example we'll use the family Accipitridae, which includes some birds of prey.\n",
        "\n",
        "First we'll load in our data. This will be the same data available for your coursework:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8REIMN8CsWlk"
      },
      "source": [
        "trait_data <- read.csv(\"coursework_trait_data.csv\")\n",
        "str(trait_data)\n",
        "head(trait_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIRVoVndt1yf"
      },
      "source": [
        "So we can see the data that we have is a near complete species list for the world's birds, with some information on body mass and beak sizes. We've included two different taxonomies, Birdlife and Jetz because range maps were available from Birdlife, but our phylogeny uses the Jetz tree.\n",
        "\n",
        "For more info on the tree, and where download your own in the future, look here:\n",
        "\n",
        "http://birdtree.org/\n",
        "\n",
        "So we'll first filter our traits based on the Jetz families."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEdd0cgIDB89"
      },
      "source": [
        "library(dplyr)\n",
        "Accip_data <- trait_data %>% filter(Jetz_family == \"Accipitridae\")\n",
        "nrow(Accip_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgpCjm0eFyRs"
      },
      "source": [
        "Now we need to load in our range data. For convinence we've saved the range data as an `.Rdata` object, which `R` can load back into the working environment. `.Rdata` objects can be extremely useful, especially when you've ran a model that's taken a long time, and wish to save the result without converting it to a specific file format. The maps for each family are saved as a separate `R.data` file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CM0IkvIFssO"
      },
      "source": [
        "# First load in the spatial packages we'll need\n",
        "library(raster)\n",
        "library(rgdal)\n",
        "library(sf)\n",
        "library(geosphere)\n",
        "\n",
        "\n",
        "# Load the data into our environment\n",
        "load(\"Accipitridae_maps.Rdata\")\n",
        "\n",
        "# Inspect the maps\n",
        "class(Accip_maps)\n",
        "head(Accip_maps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWQItUKAKcOD"
      },
      "source": [
        "You can see that the range maps are stored in a spatial dataframe. We have information for each species and ranges, stored as multiploygons. Some species have multiple rows, based on different types of ranges (i.e. breeding range, see (http://datazone.birdlife.org/species/spcdistPOS) for more information).\n",
        "\n",
        "We now want to combine different ranges for each species and calculate the range size. We can also plot the range sizes to view them at a global scale. For this practical we'll split ranges in small and large, and highlight the smaller ranges on the map. To do this we need to utilise a `for loop` to go through our maps, which may be a new concept for some of you. Don't be put off if it seems complicated! Remember you can query functions using `?` in front of functions like this: `?area`, `?subset`. You can also run each line one by one to better understand what's happening."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ck4DBHgr50OG"
      },
      "source": [
        "# Start by creating an empty raster stack to store our data in.\n",
        "raster_stack <- raster(ncols=2160, nrows = 900, ymn = -60)\n",
        "\n",
        "# And lets add columns to our data for storing range and latitude. \n",
        "Accip_data$range_size <- NA\n",
        "Accip_data$latitude <- NA\n",
        "\n",
        "# Open a for loop which will cycle through each species in our list of birdlife names. The object 'species' is just a placeholder. We could name it whatever we want, as long as we give R a sensible object to iterate through.\n",
        "# The curly brackets show the beginning and the end of the loop, which will be repeated for each species.\n",
        "for (species in Accip_data$Birdlife_Name) {\n",
        "\n",
        "  # We want to subset our range maps for each species and only the range maps in which it is present now (not historical). \n",
        "  map_data_i <- subset(Accip_maps, Accip_maps$SCINAME == species) \n",
        "  map_data_i <- subset(map_data_i, map_data_i$PRESENCE %in% c(1,2,3))\n",
        "  \n",
        "  # Combine the different ranges (Shapefiles) and convert to a Spatial Polygon.\n",
        "  map_i <- as_Spatial(st_combine(map_data_i$Shape)) \n",
        "\n",
        "  # Calculate the centroid of each range, and then extract the latitude component (Latitude midpoints). Then add to our dataframe.\n",
        "  latitude_i <- centroid(map_i)[2]\n",
        "  Accip_data[Accip_data$Birdlife_Name == species, \"latitude\"] <- latitude_i\n",
        "  \n",
        "  # Convert this Spatial Polygon into a raster with dimensions == raster_stack. Value = 1 if pixel is inside the polygon (range).\n",
        "  raster_i <- rasterize(map_i, raster_stack) \n",
        "\n",
        "  # Area asigns the pixels a value based on their size in km2\n",
        "  area_raster_i <- area(raster_i, na.rm = TRUE) \n",
        "\n",
        "  # getValues gets the values of all the pixels, sum takes the sum of these values giving final size of range. Then we'll store it.\n",
        "  area_i <- sum(getValues(area_raster_i), na.rm = TRUE)\n",
        "  Accip_data[Accip_data$Birdlife_Name == species, \"range_size\"] <- area_i\n",
        "  \n",
        "  # ifelse if for a conditional statement. If the result is TRUE it performs the first option and if FALSE it performs the second option. This assings a value of 1 to large ranges and 2 to small ranges.\n",
        "  # This is based on range sizes over 1 million km^2. You may wish to change this depending on your clade and what you think is a big range size.\n",
        "  ifelse(area_i > 1000000, raster_i[raster_i == 1] <- 1, raster_i[raster_i == 1] <- 2) \n",
        "\n",
        "  # Lastly we want to add our finished range map (coded for big and small ranges) to our stack to store for later.\n",
        "  raster_stack <- addLayer(raster_stack, raster_i)  \n",
        "\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0HENg2ecKiq"
      },
      "source": [
        "Now we've created a stack of maps for the range of each species. And at the same time generated the data we need for a pgls to investigate the relationship between range size and latitude. First we'll plot the ranges to see if there's a relationship. To do this we need to combine all our ranges, with small ranges on top of large ones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-rW6-k3J8fg"
      },
      "source": [
        "# Combine all layers in the stack together to produce a final raster_layer.\n",
        "# By using fun = max, we're asking the function to pick the highest number, which in this case is 2 (small ranges), so they'll go on top of large ones.\n",
        "# The rep function repeats 1 for each layer of our stack. We're telling stackApply to add all the rasters to the 1st new layer. If we wanted to make 2 layers we could create a vector of 1s and 2s.\n",
        "final_layer <- stackApply(raster_stack, rep(1, nlayers(raster_stack)), fun = max)\n",
        "plot(final_layer, col=rainbow(2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQIrQwweikNM"
      },
      "source": [
        "So now we can see where all the small range sizes are relative to the large ones. However, it doesn't look very pretty and countries without any ranges are left off the map. We can make a much clearer map using `ggplot2`. Again don't be worried about all the code. This is mainly for aesthetic purposes!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cA95cBHSfZbI"
      },
      "source": [
        "library(tidyr)\n",
        "library(ggplot2)\n",
        "\n",
        "# Set all zero values to NA so they are not plotted as a value.\n",
        "final_layer[which(getValues(final_layer == 0))] <- NA\n",
        "\n",
        "# Convert the raster into a raster dataframe. This will be coordinates of the raster pixels (cols x and y) and the value of the raster pixels (col index_1). Remove rows with NA values from this dataframe.\n",
        "raster_data <- as.data.frame(final_layer, xy=TRUE) %>% drop_na()\n",
        "colnames(raster_data) <- c(\"long\", \"lat\", \"index\")\n",
        "\n",
        "# Add labels for the range sizes so that ggplot colours them as discrete, rather than a continous number.\n",
        "raster_data$ranges[raster_data$index == 1] <- \"Large\"\n",
        "raster_data$ranges[raster_data$index == 2] <- \"Small\"\n",
        "\n",
        "# We can then plot this in ggplot. We have to first create the color scheme for our map.\n",
        "myColors <- c(\"grey80\", \"red\")\n",
        "\n",
        "# Assign names to these colors that correspond to each range size.\n",
        "names(myColors) <- unique(raster_data$ranges)\n",
        "\n",
        "# Create the color scale.\n",
        "colScale <- scale_fill_manual(name = \"Range Sizes\", values = myColors)\n",
        "\n",
        "\n",
        "# Create a plot with ggplot (the plus signs at the end of a line carry over to the next line).\n",
        "range_plot <- ggplot() +\n",
        "  # borders imports all the country outlines onto the map. colour changes the color of the outlines, fill changes the color of the insides of the countries\n",
        "  # this will grey out any terrestrial area which isn't part of a range.\n",
        "  borders(ylim = c(-60,90), fill = \"grey90\", colour = \"grey90\") +\n",
        "  \n",
        "  # Borders() xlim is -160/200 to catch the edge of russia. We need to reset the xlim to -180/180 to fit our raster_stack.\n",
        "  xlim(-180, 180) + \n",
        "  \n",
        "  # Add the range information on top.\n",
        "  geom_tile(aes(x=long, y=lat, fill= ranges), data=raster_data) +\n",
        "  colScale +\n",
        "  ggtitle(\"Small range sizes in the Accipitidae\") + \n",
        "  theme_classic() +\n",
        "  ylab(\"Latitude\") + \n",
        "  xlab(\"Longitude\") + coord_fixed() # coord_fixed() makes ggplot keep our aspect ratio the same, rather than stretching the plot to fit all available space.\n",
        "\n",
        "# Return the plot so we can view it.\n",
        "range_plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tY7sksy5rmiz"
      },
      "source": [
        "That looks much better than the first. Experiment with your own maps to create a map for your report. Try changing how you show ranges, such as what detirmines if a range is large or small, or anything else you can think of! You can save your plots as a file using different formats like a jpeg. Watch out for how the map transforms when it's saved and edit your plots accordingly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U64e_8cVs4DW"
      },
      "source": [
        "# Open up a new plotting device which will save a photo.\n",
        "jpeg(\"my_map.jpeg\")\n",
        "\n",
        "# Add the plot to the plotting device.\n",
        "range_plot\n",
        "\n",
        "# Turn off the plotting device to save it.\n",
        "dev.off()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YpPmREctldg"
      },
      "source": [
        "From this practical you should be able to run a pgls using the data we've generated and a species tree. You'll have to explore your data and potentially transform variables. You should also have all the code to cut down your tree. You can find a tree for all Jetz species on blackboard called \"all_birds.tre\", or you can download your own from:\n",
        "\n",
        "http://birdtree.org/\n",
        "\n",
        "### 5. Latitudinal Diversity Gradient\n",
        "\n",
        "Another question you might pick for your coursework is to investigate the latitudinal diversity gradient for your chosen taxa. We'll explore the same relationship with Accipitridae. We've already extracted latitude but we for this model we will lump species into bins at 5 degree latitudes and see if some bins are bigger closer to the equator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_qT6xTWvmGy"
      },
      "source": [
        "# First we need to get absolute latitude.\n",
        "Accip_data$abs.latitude <- abs(Accip_data$latitude)\n",
        "\n",
        "# First lets create a bin range (from 0 to 90 which is max latitude) and size (by=5)\n",
        "range <- seq(0, 90, by=5) \n",
        "\n",
        "# Create labels for our bins. We want to skip zero, as the labels refer to the upper limits of each break. \n",
        "labels <- seq(5, 90, 5)\n",
        "\n",
        "# We can now 'cut' up our latitude and put them into bins. This function adds an extra column, and adds a label for which bin each species should be in.\n",
        "Accip_data$lat.bins <- cut(Accip_data$abs.latitude, breaks=range, labels=labels) \n",
        "\n",
        "# The cut function creates the labels as factors, so we'll turn them back into numbers to plot. We turn them into characters first because as.numeric will convert factors into their level order, rather than the value they are.\n",
        "Accip_data$lat.bins <- as.numeric(as.character(Accip_data$lat.bins))\n",
        "\n",
        "# Plot our bins as a histogram\n",
        "hist(Accip_data$lat.bins, breaks = 7) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WdO7RMtyse6"
      },
      "source": [
        "It deffinetly looks like a pattern is going on there! We can investigate this using a model. Because the data is count, it looks like it has a poisson distribution. For this reason we might want to utilise a generalised linear model instead. Also because we've binned species, we won't use a pgls for this question. First lets generate species richness."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYZewnwizPNo"
      },
      "source": [
        "# Get the frequency of each bin\n",
        "species_richness <- count(Accip_data, lat.bins)\n",
        "colnames(species_richness)[2] <- \"richness\"\n",
        "species_richness"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vd_I_DaN16Ty"
      },
      "source": [
        "Now to run a glm, using a poisson error structure given our data is very skewed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gj_zQYW08GO"
      },
      "source": [
        "# The only difference with running a glm is now we have to specify the family as well.\n",
        "accip_model <- glm(richness ~ lat.bins, data = species_richness, family = \"poisson\")\n",
        "summary(accip_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aBe5ql73Z6D"
      },
      "source": [
        "You should be able to figure out if there's a relationship there! One thing to remember about a glm is that we've applied a link function. For a poisson model this a log-link function. This means that the relationship between our variables isn't as simple as a 0.03 decrease in species richness with degree of latitude. The rate of change of species richness is different at different latitudes. We can see this relationship by plotting our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0GG-yba2l6H"
      },
      "source": [
        "plot(richness ~ lat.bins, data = species_richness)\n",
        "lines(species_richness$lat.bins, accip_model$fitted.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N60Obw6C-Xi-"
      },
      "source": [
        "Lastly, you might also want to plot a map of species richness to go alongside your plot. For this we just have to slightly change our raster stack. Before we had large and small ranges as 1 and 2, but we want to change them all to 1 so we can add up overlapping ranges to get a measure of species richness."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DD8YWSvG9TiN"
      },
      "source": [
        "# We'll loop through each layer and change all the values to the 1. By specifying values greater than zero we make sure we only change values that are in a species range.\n",
        "# Notice for this loop we're using \"i\" as placeholder, which will iterate from 1 to 247 (number of raster layers)\n",
        "for (i in 1:nlayers(raster_stack)) {\n",
        "  # Pull out the raster.\n",
        "  raster_i <- raster_stack[[i]]\n",
        "  # Change the values to 1.\n",
        "  raster_i[raster_i > 0] <- 1\n",
        "  # Put the raster back in the stack.\n",
        "  raster_stack[[i]] <- raster_i\n",
        "}\n",
        "\n",
        "# Then we can make a new final layer, but we change the function to sum, because we want to add up ranges instead of taking the max.\n",
        "final_layer <- stackApply(raster_stack, rep(1, nlayers(raster_stack)), fun = sum)\n",
        "\n",
        "# Plot the layer.\n",
        "plot(final_layer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJhuDhadDpoN"
      },
      "source": [
        "Again we can make this map nicer!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8zNmaqDDsZK"
      },
      "source": [
        "# Set all zero values to NA so they are not plotted as a value.\n",
        "final_layer[which(getValues(final_layer == 0))] <- NA\n",
        "\n",
        "# Convert the raster into a raster dataframe. This will be coordinates of the raster pixels (cols x and y) and the value of the raster pixels (col index_1). Remove rows with NA values from this dataframe.\n",
        "raster_data <- as.data.frame(final_layer, xy=TRUE) %>% drop_na()\n",
        "colnames(raster_data) <- c(\"long\", \"lat\", \"richness\")\n",
        "\n",
        "# Plot with ggplot.\n",
        "richness_plot <- ggplot() +\n",
        "  borders(ylim = c(-60,90), fill = \"grey90\", colour = \"grey90\") +\n",
        "  xlim(-180, 180) + \n",
        "  geom_tile(aes(x=long, y=lat, fill= richness), data=raster_data) +\n",
        "  scale_fill_gradientn(name = \"Species Richness\", colors = c(\"skyblue\", \"red\")) +\n",
        "  ggtitle(\"Accipitridae Species Richness Heat Map\") + \n",
        "  theme_classic() +\n",
        "  ylab(\"Latitude\") + \n",
        "  xlab(\"Longitude\") + \n",
        "    theme_classic() +\n",
        "  ylab(\"Latitude\") + \n",
        "  xlab(\"Longitude\") + coord_fixed()\n",
        "\n",
        "# Return the plot so we can view it.\n",
        "richness_plot"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}